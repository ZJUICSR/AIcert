webpackJsonp([10],{"3Vw4":function(m,o,t){m.exports=t.p+"static/img/afterDebias.e80336b.png"},"9fSZ":function(m,o,t){m.exports=t.p+"static/img/beforeDebias.fab946e.png"},Azza:function(m,o){},gMNX:function(m,o,t){"use strict";Object.defineProperty(o,"__esModule",{value:!0});var e=t("BO1k"),a=t.n(e),s=t("gRE1"),i=t.n(s),r=t("mvHQ"),n=t.n(r),l=t("R45V"),c=t("83tA"),h=t("P/9i"),d=t("T9rv"),v=t("UI/F"),f=t("FaAE"),w=t("oh/m"),u=t.n(w),p=t("2b9l"),_=t.n(p),y=t("GL62"),g=t.n(y),b=t("s1jE"),x=t.n(b),C={template:'\n        <svg t="1680138013828" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4354" width="128" height="128"><path d="M534.869333 490.496a1403.306667 1403.306667 0 0 0 50.858667-25.813333c16.042667-8.618667 29.013333-15.061333 38.570667-19.029334 9.557333-3.925333 17.066667-6.058667 22.869333-6.058666 9.557333 0 17.749333 3.2 24.917333 10.026666 6.826667 6.826667 10.581333 15.061333 10.581334 25.088 0 5.76-1.706667 11.818667-5.12 17.92-3.413333 6.101333-7.168 10.069333-10.922667 11.861334-35.157333 14.677333-74.410667 25.429333-116.736 31.872 7.850667 7.168 17.066667 17.237333 28.330667 29.781333 11.264 12.544 17.066667 18.986667 17.749333 20.053333 4.096 6.101333 9.898667 13.653333 17.408 22.613334 7.509333 8.96 12.629333 15.786667 15.36 20.778666 2.730667 5.034667 4.437333 11.093333 4.437333 18.304a33.706667 33.706667 0 0 1-9.898666 24.021334 33.834667 33.834667 0 0 1-25.6 10.410666c-10.24 0-22.186667-8.618667-35.157334-25.472-12.970667-16.512-30.037333-46.933333-50.517333-91.050666-20.821333 39.424-34.816 65.962667-41.642667 78.506666-7.168 12.544-13.994667 22.186667-20.48 28.672a30.976 30.976 0 0 1-22.528 9.685334 32.256 32.256 0 0 1-25.258666-11.093334 35.413333 35.413333 0 0 1-9.898667-23.68c0-7.893333 1.365333-13.653333 4.096-17.578666 25.258667-35.84 51.541333-67.413333 78.848-93.568a756.650667 756.650667 0 0 1-61.44-12.544 383.061333 383.061333 0 0 1-57.685333-20.48c-3.413333-1.749333-6.485333-5.717333-9.557334-11.818667a30.208 30.208 0 0 1-5.12-16.853333 32.426667 32.426667 0 0 1 10.581334-25.088 33.152 33.152 0 0 1 24.234666-10.026667c6.485333 0 14.677333 2.133333 24.576 6.101333 9.898667 4.266667 22.186667 10.026667 37.546667 18.261334 15.36 7.893333 32.426667 16.853333 51.882667 26.538666-3.413333-18.261333-6.485333-39.082667-8.874667-62.378666-2.389333-23.296-3.413333-39.424-3.413333-48.042667 0-10.752 3.072-19.712 9.557333-27.264A30.677333 30.677333 0 0 1 512.341333 341.333333c9.898667 0 18.090667 3.925333 24.576 11.477334 6.485333 7.893333 9.557333 17.92 9.557334 30.464 0 3.584-0.682667 10.410667-1.365334 20.48-0.682667 10.368-2.389333 22.570667-4.096 36.906666-2.048 14.677333-4.096 31.146667-6.144 49.834667z" fill="#FF3838" p-id="4355"></path></svg>\n        '},M={template:'\n            <a-icon :component="selectSvg" />\n        ',data:function(){return{selectSvg:C}}},P={name:"modelfairnessdebias",components:{navmodule:l.a,func_introduce:c.a,showLog:d.a,resultDialog:v.a,fairnessDataset:h.a,selectIcon:M},data:function(){return{htmlTitle:"模型公平性提升报告",rowkey:0,colkey:0,debiasMethodValue:"",methodDesShow:[!1,!1,!1,!1,!1,!1,!1,!1],evamethod:{DI:{name:"Dsiaprate Impact(DI)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},DP:{name:"Demographic Parity(DP)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mo stretchy="false">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">|</mo></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},FPd:{name:"False Positive Difference(FPd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},FPr:{name:"False Positive Ratio(FPr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},FNd:{name:"False Negative Difference(FNd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},FNr:{name:"False Negative Ratio(FNr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},TPd:{name:"True Positive Difference(TPd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},TPr:{name:"True Positive Ratio(TPr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},TNd:{name:"True Negative Difference(TNd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},TNr:{name:"True Negative Ratio(TNr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mi>Y</mi><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},FOd:{name:"False Omission Difference(FOd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},FOr:{name:"False Omission Ratio(FOr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>0</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},FDd:{name:"False Discovery Difference(FDd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},FDr:{name:"False Discovery Ratio(FDr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},PRd:{name:"Precision Difference(PRd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},F1d:{name:"F1 Score Difference(F1d)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mfrac><mrow><mn>2</mn><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mfrac><mrow><mn>2</mn><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></mfrac><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},PE:{name:"Predictive Equality",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},EOD:{name:"Equal Odds",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mstyle displaystyle="false" scriptlevel="0"><munder><mo data-mjx-texclass="OP">∑</mo><mrow><mi>y</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></munder></mstyle></mrow><mrow><mo stretchy="false">|</mo></mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mi>y</mi><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'},PP:{name:"Predictive Parity",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo>∣</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},EOP:{name:"Equal Opportunity",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>=</mo><mn>1</mn><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},OMd:{name:"Overall Misclassification Difference(OMd)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">|</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo data-mjx-texclass="CLOSE">|</mo></mrow></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>0</mn><mo>，则模型越公平</mo></math>'},OMr:{name:"Overall Misclassification Ratio(OMr)",formula:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>≠</mo><mi>Y</mi><mo>∣</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></math>',des:'<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>Y</mi><mo stretchy="false">^</mo></mover></mrow><mo>为模型预测结果，</mo><mi>Z</mi><mo>为保护属性（如种族），</mo><mn>0</mn><mo>代表劣势群体（如白人），</mo><mn>1</mn><mo>代表优势群体（如有色人种），</mo><mi>P</mi><mo>为概率，该计算结果越接近</mo><mn>1</mn><mo>，则模型越公平</mo></math>'}},imgEvaMethod:[[{name:"mPre",description:""},{name:"mFPR",description:""},{name:"mFNR",description:""},{name:"mTNR",description:""}],[{name:"mTPR",description:""},{name:"mAcc",description:""},{name:"mF1",description:""},{name:"mBA",description:""}]],methodHoverIndex:-1,methodDescription:"",debiasMethod:{"Adersarial Debiasing":{name:"Adversarial Debiasing(FAD)",des:"对抗训练纠偏算法是一种训练过程中的纠偏技术，可以使训练的分类器在最大化预测准确率的同时减少能从其预测结果中与保护属性相关的信息。这种训练算法时公平的，因为无法从它的预测结果中获取到与保护属性相关的信息。",class:["table"]},"Reject Option-SPd":{name:"Reject Option Classification-SPd",des:"一种后处理技术，对于在不确定性最高的决策边界周围的样本，算法会以最小化统计均等差（Statistical parity difference）为目标，给出对劣势群体有利的结果和对优势群体不利的结果，从而缓解模型偏见。",class:["table"]},"Reject Option-AOd":{name:"Reject Option Classification-AOd",des:"一种后处理技术，对于在不确定性最高的决策边界周围的样本，算法会以最小化平均概率差（Average odds difference）为目标，给出对劣势群体有利的结果和对优势群体不利的结果，从而缓解模型偏见",class:["table"]},"Reject Option-EOd":{name:"Reject Option Classification-EOd",des:"一种后处理技术，对于在不确定性最高的决策边界周围的样本，算法会以最小化同等机遇差（Equal opportunity difference）为目标，给出对劣势群体有利的结果和对优势群体不利的结果，从而缓解模型偏见",class:["table"]},"Calibrated EOD-fnr":{name:"Calibrat Edequalized Odds-fnr",des:"一种后处理技术，以使不同种群的预测结果具有相同的fnr（假阴性率）为目标，优化分类器输出的分数，从而满足公平性指标。",class:["table"]},"Calibrated EOD-fpr":{name:"Calibrat Edequalized Odds-fpr",des:"一种后处理技术，以使不同种群的预测结果具有相同的fpr（假阳性率）为目标，优化分类器输出的分数，从而满足公平性指标。",class:["table"]},"Calibrated EOD-weighted":{name:"Calibrat Edequalized Odds-weighted",des:"一种后处理技术，以使不同种群的预测结果具有相同的fnr（假阴性率）和fpr（假阳性率）为目标，优化分类器输出的分数，从而满足公平性指标。",class:["table"]},domain_independent:{name:"Domain Independent Training",des:"领域独立训练方法受到一种名为“解耦分类器”的技术的启发，通过让模型在训练过程中忽视数据中的偏见信息，从而减少模型对偏见的依赖。优点是可以有效地减少模型的性别偏见",class:["pic","table"]},domain_discriminative:{name:"Domain Adversarial Training",des:"领域对抗性训练方法试图通过引入一个对抗性的学习过程来减少模型对偏见的依赖。具体来说，模型在训练过程中不仅要尽可能地准确预测目标标签，还要尽可能地忽视数据中的偏见信息。",class:["pic"]},uniconf_adv:{name:"Domain Conditional Training",des:"领域条件训练类似于InclusiveFaceNet的训练方式，通过在训练过程中显式地考虑数据中的偏见信息，使模型能够在不同的子群体中都有良好的性能。优点是可以有效地减少模型对偏见的依赖。",class:["pic"]}},radioStyle:{display:"block",lineHeight:"30px",width:"100%"},heat_height:"213px",buttonBGColor:{background:"#0B55F4",color:"#FFFFFF"},disStatus:!1,propTextsub:"",logflag:!1,percent:10,logtext:[],dataname:["German","Adult","Compas","Cifar10-S","CelebA"],dataNameValue:0,senAttrList:[],tarAttrList:[],staAttrList:[],funcDesText:{name:"模型公平性提升",imgpath:u.a,bgimg:_.a,destext:"模型预测存在偏见，通过公平性提升功能，缓解模型偏见",backinfo:"模型公平性提升功能通过对抗训练纠偏技术、领域独立训练、拒绝选项分类、等几率校准等方法缓解模型偏见，使用各类评估方法对提升前后的模型进行公平性评估，直观展示提升效果",highlight:["支持表格数据集和图片数据集，表格数据集：German，Adult，Compas；图片数据集：CelebA，Cifar10-S","支持22种评估算法从群体公平性、个体公平性两大维度对比模型提升前后的公平程度","支持8种模型公平性提升算法，如对抗训练纠偏算法、领域独立训练算法、3种拒绝选项分类、3种等几率校准算法"]},isShowPublish:!1,res:{score:{bef:null,aft:null},consistency_score:{bef:null,aft:null},group_score:{bef:null,aft:null},score_con:{bef:null,aft:null},score_evaluate:{bef:null,aft:null},Consistency:{bef:null,aft:null},consText:"",attrEvaValue:{bef:{},aft:{}},labels:[],groupText:{}},result:{},evaCheckedValues:[],evaImgCheckedValues:[],logclk:"",tid:"",stidlist:[],debiasDisabled:{domain_discriminative:!1,uniconf_adv:!1,domain_independent:!1,"Adersarial Debiasing":!1,"Reject Option-SPd":!1,"Reject Option-AOd":!1,"Reject Option-EOd":!1,"Calibrated EOD-fnr":!1,"Calibrated EOD-fpr":!1,"Calibrated EOD-weighted":!1},postData:{},disablestyle:{color:"rgba(0,0,0,.25)","background-color":"#f5f5f5"}}},watch:{isShowPublish:{immediate:!0,handler:function(m){m?this.noScroll():this.canScroll()}}},created:function(){document.title="模型公平性提升"},beforeDestroy:function(){this.clk&&window.clearInterval(this.clk),this.logclk&&window.clearInterval(this.logclk)},mounted:function(){},methods:{defenseShow:function(){var m=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"[]";return JSON.parse(m).join("、")},changeMethods:function(m,o){var t=document.getElementById("button"+m+o);""==t.style.color?(this.methodHoverIndex=m,this.methodDescription=this.imgEvaMethod[m][o].description,t.style.color="#0B55F4",t.style.background="#E7F0FD",this.evaImgCheckedValues.push(this.imgEvaMethod[m][o].name)):(this.methodHoverIndex=-1,this.methodDescription="",t.style.color="",t.style.borderColor="#C8DCFB",t.style.background="#F2F4F9",t.blur(),this.evaImgCheckedValues.splice(this.evaImgCheckedValues.indexOf(this.imgEvaMethod[m][o].name),1))},disableImgMehod:function(){for(var m in this.imgEvaMethod)for(var o in this.imgEvaMethod[m]){var t=document.getElementById("button"+m+o);this.methodHoverIndex=-1,this.methodDescription="",t.style.color="rgba(0,0,0,.25)",t.style.borderColor="#C8DCFB",t.style.background="#f5f5f5",t.blur()}this.evaImgCheckedValues=[]},ableImgMehod:function(){for(var m in this.imgEvaMethod)for(var o in this.imgEvaMethod[m]){var t=document.getElementById("button"+m+o);this.methodHoverIndex=-1,this.methodDescription="",t.style.color="",t.style.borderColor="#C8DCFB",t.style.background="#F2F4F9",t.blur()}},getLog:function(){var m=this;m.percent<99&&(m.percent+=1),m.$axios.get("/Task/QueryLog",{params:{Taskid:m.tid}}).then(function(o){if("{}"==n()(m.stidlist))m.logtext=[i()(o.data.Log).slice(-1)[0]];else for(var t in m.logtext=[],m.stidlist)m.logtext.push(o.data.Log[m.stidlist[t]])})},getData:function(){var m=this;m.$axios.get("/output/Resultdata",{params:{Taskid:m.tid}}).then(function(o){console.log("dataget:",o),m.result=o})},stopTimer:function(){1==this.result.data.stop?(this.percent=100,this.logflag=!1,window.clearInterval(this.clk),window.clearInterval(this.logclk),this.isShowPublish=!0,["German","Adult","Compas"].indexOf(this.dataname[this.dataNameValue])>-1?this.result=this.result.data.result.model_debias:this.result=this.result.data.result,this.resultPro(this.result)):2==this.result.data.stop&&(this.percent=100,window.clearInterval(this.clk),window.clearInterval(this.logclk))},update:function(){this.getData();try{this.stopTimer()}catch(m){}},closeDialog:function(){this.isShowPublish=!1},onChangeEvaMethod:function(m){console.log("checked = ",m),this.evaCheckedValues=m},onChangeDebiasMethod:function(m){console.log("debiasMethodValue:",this.debiasMethodValue)},clientDatasetSelect:function(m,o,t,e){this.dataNameValue=m,this.senAttrList=o,this.tarAttrList=t,this.staAttrList=e,0==o.length||0==t.length||0==e.length?this.buttonBGColor.background="#C8DCFB":this.buttonBGColor.background="#0B55F4",this.debiasDisabled={domain_discriminative:!1,uniconf_adv:!1,domain_independent:!1,"Adersarial Debiasing":!1,"Reject Option-SPd":!1,"Reject Option-AOd":!1,"Reject Option-EOd":!1,"Calibrated EOD-fnr":!1,"Calibrated EOD-fpr":!1,"Calibrated EOD-weighted":!1},-1==["Cifar10-S","CelebA"].indexOf(this.dataname[m])?(this.debiasDisabled.domain_discriminative=!0,this.debiasDisabled.uniconf_adv=!0,this.disableImgMehod(),["domain_discriminative","uniconf_adv"].indexOf(this.debiasMethodValue)>-1&&(this.debiasMethodValue="domain_independent")):(this.ableImgMehod(),this.debiasDisabled={domain_discriminative:!1,uniconf_adv:!1,domain_independent:!1,"Adersarial Debiasing":!0,"Reject Option-SPd":!0,"Reject Option-AOd":!0,"Reject Option-EOd":!0,"Calibrated EOD-fnr":!0,"Calibrated EOD-fpr":!0,"Calibrated EOD-weighted":!0},-1==["domain_discriminative","uniconf_adv"].indexOf(this.debiasMethodValue)&&(this.debiasMethodValue="domain_independent")),console.log("this.dataname:",m),console.log("this.debiasDisabled:",this.debiasDisabled)},checkboxMouseEnter:function(m,o){this.rowkey=m-1,this.colkey=o-1,this.methodDesShow=[!1,!1,!1,!1,!1,!1,!1,!1],this.methodDesShow[this.rowkey]=!0},resultPro:function(m){if(this.percent=100,this.res.labels=[],"Consistency"in this.result?(this.res.score.bef=100*this.result["Overall fairness"][0].toFixed(2),this.res.score.aft=100*this.result["Overall fairness"][1].toFixed(2)):(this.res.score.bef=100*this.result.model_evaluate["Overall fairness"].toFixed(2),this.res.score.aft=100*this.result.model_debias["Overall fairness"].toFixed(2)),this.res.score.bef>80?(this.res.score_evaluate.bef="优秀",this.res.score_con.bef="公平"):this.res.score.bef>60&&this.res.score.bef<=80?(this.res.score_evaluate.bef="良好",this.res.score_con.bef="较公平"):(this.res.score_evaluate.bef="差",this.res.score_con.bef="较不公平"),this.res.score.aft>80?(this.res.score_evaluate.aft="优秀",this.res.score_con.aft="公平"):this.res.score.aft>60&&this.res.score.aft<=80?(this.res.score_evaluate.aft="良好",this.res.score_con.aft="较公平"):(this.res.score_evaluate.aft="差",this.res.score_con.aft="较不公平"),"Consistency"in this.result){this.res.consistency_score.bef=100*this.result["Overall individual fairness"][0].toFixed(2),this.res.consistency_score.aft=100*this.result["Overall individual fairness"][1].toFixed(2),this.res.group_score.bef=100*this.result["Overall group fairness"][0].toFixed(2),this.res.group_score.aft=100*this.result["Overall group fairness"][1].toFixed(2),this.res.Consistency.bef=(100*this.result.Consistency[0]).toFixed(2),this.res.Consistency.aft=(100*this.result.Consistency[1]).toFixed(2),this.res.Proportion=this.result.Proportion;var o=(this.res.Consistency.aft-this.res.Consistency.bef).toFixed(2);Object(f.q)("consevaBef",this.res.Consistency.bef,"#0B55F4","Original"),Object(f.q)("consevaAft",this.res.Consistency.aft,"#0B55F4","Improved"),this.res.consText="模型个体公平性提升前得分为"+this.res.Consistency.bef+",提升后的得分为"+this.res.Consistency.aft+"共提升了"+o+"分。";var t=!0,e=!1,s=void 0;try{for(var i,r=a()(this.senAttrList);!(t=(i=r.next()).done);t=!0){var n=i.value;this.res.attrEvaValue.bef[n]=[],this.res.attrEvaValue.aft[n]=[]}}catch(m){e=!0,s=m}finally{try{!t&&r.return&&r.return()}finally{if(e)throw s}}for(var l in this.result)if("Consistency"!=l&&"Proportion"!=l&&"Corelation coefficients"!=l&&"stop"!=l&&-1==l.indexOf("Overall")&&-1==l.indexOf("score")){for(var c in this.res.labels.push(l),this.result[l][0])this.res.attrEvaValue.bef[c].push(this.result[l][0][c].toFixed(2));for(var h in this.result[l][1])this.res.attrEvaValue.aft[h].push(this.result[l][1][h].toFixed(2))}var d=!0,v=!1,w=void 0;try{for(var u,p=a()(this.senAttrList);!(d=(u=p.next()).done);d=!0){var _=u.value;Object(f.o)(_,this.res.attrEvaValue.bef[_],this.res.attrEvaValue.aft[_],this.res.labels,"群体公平性评估指标"),this.res.groupText[_]="本次测试敏感属性为"+_+"，目标属性为"+this.tarAttrList.toString()+"                    ，直方图根据"+this.res.labels.toString()+"算法评估结果绘制。"}}catch(m){v=!0,w=m}finally{try{!d&&p.return&&p.return()}finally{if(v)throw w}}var y={id:"center_"+this.dataname[this.dataNameValue],label:this.dataname[this.dataNameValue],population:1,children:[]};for(var b in this.result.Proportion){var C={id:"second_"+b,label:b,population:1,children:[]};for(var M in this.result.Proportion[b]){var P={id:M,label:M,population:this.result.Proportion[b][M].toFixed(3),isLeaf:!0};C.children.push(P)}y.children.push(C)}Object(f.h)("pro_tree",y,g.a,x.a);var Y=[],k={},O=[],D=[],E=[],L=[],F=0,S=!0,Z=!1,N=void 0;try{for(var j,A=a()(this.result["Corelation coefficients"]);!(S=(j=A.next()).done);S=!0){var I=j.value;-1==Y.indexOf(I.attr)&&(k[I.attr]=F,Y.push(I.attr),F+=1),-1==Y.indexOf(I.target)&&(k[I.target]=F,Y.push(I.target),F+=1),null!=I.values.pearson&&O.push([k[I.attr],k[I.target],I.values.pearson.toFixed(3)]),null!=I.values.spearman&&D.push([k[I.attr],k[I.target],I.values.spearman.toFixed(3)]),null!=I.values.kendalltau&&E.push([k[I.attr],k[I.target],I.values.kendalltau.toFixed(3)]),null!=I.values.mutual_info&&L.push([k[I.attr],k[I.target],I.values.mutual_info.toFixed(3)])}}catch(m){Z=!0,N=m}finally{try{!S&&A.return&&A.return()}finally{if(Z)throw N}}F>5&&(this.heat_height=48*F+"px");Object(f.c)("NMI",Y,L,["rgba(206, 221, 253, 1)","rgba(157, 187, 251, 1)","rgba(60, 119, 246, 1)","rgba(11, 85, 244, 1)","rgba(7, 51, 146, 1)"]),Object(f.c)("person",Y,O,["rgba(253, 206, 236, 1)","rgba(251, 157, 218, 1)","rgba(247, 84, 190, 1)","rgba(244, 11, 162, 1)","rgba(195, 9, 130, 1)"]),Object(f.c)("spearman",Y,D,["rgba(223, 206, 253, 1)","rgba(191, 157, 251, 1)","rgba(142, 84, 247, 1)","rgba(94, 11, 244, 1)","rgba(56, 7, 146, 1)"]),Object(f.c)("Kendall",Y,E,["rgba(253, 227, 206, 1)","rgba(251, 199, 157, 1)","rgba(247, 158, 84, 1)","rgba(244, 116, 11, 1)","rgba(146, 70, 7, 1)"])}else{for(var l in this.res.attrEvaValue.bef=[],this.res.attrEvaValue.aft=[],this.result.model_debias)"Consistency"!=l&&"Proportion"!=l&&"Corelation coefficients"!=l&&"stop"!=l&&-1==l.indexOf("Overall")&&-1==l.indexOf("score")&&(this.res.labels.push(l),this.res.attrEvaValue.bef.push(this.result.model_evaluate[l].toFixed(2)),this.res.attrEvaValue.aft.push(this.result.model_debias[l].toFixed(2)));Object(f.o)("evaBar",this.res.attrEvaValue.bef,this.res.attrEvaValue.aft,this.res.labels,"群体公平性评估指标"),this.res.groupText.evaBar="本次测试结果如上，直方图根据"+this.res.labels.toString()+"算法评估结果绘制。"}},initParam:function(){this.logtext=[],this.percent=0,this.postData={},this.result={},this.tid="",this.stidlist={},""!=this.clk&&(window.clearInterval(this.clk),this.clk=""),""!=this.logclk&&(window.clearInterval(this.logclk),this.logclk="")},dataEvaClick:function(){this.initParam();var m=[];if(["German","Adult","Compas"].indexOf(this.dataname[this.dataNameValue])>-1?(m=this.evaCheckedValues,"domain_independent"==this.debiasMethodValue&&(this.debiasMethodValue="Domain Independent")):m=this.evaImgCheckedValues,0==this.senAttrList.length)return this.$message.warning("请在数据集里面至少选择一项敏感属性！",3),0;if(0==this.tarAttrList.length)return this.$message.warning("请在数据集里面选择一项目标属性！",3),0;if(this.tarAttrList.length>1)return this.$message.warning("模型公平性提升只能选择一项目标属性！",3),0;if(0==this.staAttrList.length)return this.$message.warning("请在数据集里面至少选择一项统计属性！",3),0;if(0==m.length)return this.$message.warning("请在评估算法中至少选择一项评估算法！",3),0;if(""==this.debiasMethodValue)return this.$message.warning("请在提升算法中至少选择一项提升算法！",3),0;this.logflag=!0;var o=this;o.percent=20,this.$axios.post("/Task/CreateTask",{AttackAndDefenseTask:0}).then(function(t){console.log(t),o.tid=t.data.Taskid,o.postData={dataname:o.dataname[o.dataNameValue],senAttrList:n()(o.senAttrList),tarAttrList:o.tarAttrList[0],staAttrList:n()(o.staAttrList),metrics:n()(m),modelname:"3 Hidden-layer FCN",algorithmname:o.debiasMethodValue,test_mode:!1,tid:o.tid},console.log(o.postData),o.percent=40,o.logflag=!0,["Cifar10-S","CelebA"].indexOf(o.postData.dataname)>-1&&(o.postData.modelname="Resnet50",o.$axios.post("/ModelFairnessEvaluate",o.postData).then(function(m){o.stidlist.ModelFairnessEvaluate=m.data.stid,o.logclk=window.setInterval(function(){o.getLog()},2e3),o.clk=window.setInterval(function(){o.update()},6e3),console.log(o.logflag)}).catch(function(m){console.log(m),window.clearInterval(o.clk),window.clearInterval(o.logclk)})),o.$axios.post("ModelFairnessDebias",o.postData).then(function(m){o.stidlist.ModelFairnessDebias=m.data.stid,""==o.logclk&&(o.logclk=window.setInterval(function(){o.getLog()},2e3),o.clk=window.setInterval(function(){o.update()},6e3))}).catch(function(m){console.log(m),window.clearInterval(o.clk),window.clearInterval(o.logclk)})}).catch(function(m){console.log(m)})}}},Y={render:function(){var m=this,o=m.$createElement,e=m._self._c||o;return e("div",[e("a-layout",[e("a-layout-header",[e("navmodule")],1),m._v(" "),e("a-layout-content",[e("func_introduce",{attrs:{funcDesText:m.funcDesText}}),m._v(" "),e("div",{staticClass:"paramCon"},[e("h2",{staticClass:"subTitle",staticStyle:{"margin-top":"-96px"}},[m._v("参数配置")]),m._v(" "),e("div",{staticClass:"funcParam"},[e("div",{staticClass:"paramTitle"},[e("img",{staticClass:"paramIcom",attrs:{src:m.funcDesText.imgpath,alt:m.funcDesText.name}}),m._v(" "),e("h3",[m._v(m._s(m.funcDesText.name))]),m._v(" "),e("a-button",{staticClass:"DataEva",style:m.buttonBGColor,attrs:{disabled:m.disStatus},on:{click:m.dataEvaClick}},[e("a-icon",{attrs:{type:"security-scan"}}),m._v("\n                       评估\n                   ")],1)],1),m._v(" "),e("a-divider"),m._v(" "),e("div",{staticClass:"inputdiv"},[e("fairnessDataset",{attrs:{dataname:m.dataname},on:{clientDatasetSelect:m.clientDatasetSelect}}),m._v(" "),e("div",{staticClass:"model"},[e("p",{staticClass:"mainParamName"},[e("select-icon",{attrs:{stlye:{width:"4px"}}}),m._v("请选择模型结构")],1),m._v(" "),["German","Adult","Compas"].indexOf(m.dataname[m.dataNameValue])>-1?e("a-radio",{style:m.radioStyle,attrs:{defaultChecked:"",disabled:""}},[m._v("\n                           3 Hidden-layer FCN\n                       ")]):e("a-radio",{style:m.radioStyle,attrs:{defaultChecked:"",disabled:""}},[m._v("\n                           Resnet50\n                       ")])],1),m._v(" "),e("div",{staticClass:"selectDebiasMethod"},[e("p",{staticClass:"mainParamName"},[e("select-icon",{attrs:{stlye:{width:"4px"}}}),m._v("请选择公平性提升算法")],1),m._v(" "),e("a-radio-group",{on:{change:function(o){return m.onChangeDebiasMethod(o)}},model:{value:m.debiasMethodValue,callback:function(o){m.debiasMethodValue=o},expression:"debiasMethodValue"}},m._l(m.debiasMethod,function(o,t){return e("div",{key:t,staticClass:"debiasModule"},[e("a-radio",{style:m.radioStyle,attrs:{value:t,disabled:m.debiasDisabled[t]}},[m._v("\n                                   "+m._s(o.name)+"\n                               ")]),m._v(" "),m.debiasMethodValue===t?e("div",{staticClass:"formulaDes"},[m._v("\n                                   "+m._s(o.name)+"："+m._s(o.des)+"\n\n                               ")]):m._e()],1)}),0)],1),m._v(" "),e("div",{staticClass:"selectMethod"},[e("p",{staticClass:"mainParamName"},[e("select-icon",{attrs:{stlye:{width:"4px"}}}),m._v("请选择评估算法（可多选）")],1),m._v(" "),e("div",{staticClass:"methodDes"},[e("a-checkbox-group",{attrs:{disabled:!(["German","Adult","Compas"].indexOf(m.dataname[m.dataNameValue])>-1)},on:{change:m.onChangeEvaMethod}},m._l(8,function(o){return e("a-row",{attrs:{type:"flex",justify:"space-around"}},[m._l(o>6?2:3,function(t){return e("a-col",{attrs:{span:o>6?12:8}},[o>6&&18+2*(o-7)+t-1<22?e("a-checkbox",{attrs:{value:Object.keys(m.evamethod)[18+2*(o-7)+t-1]}},[e("div",{class:18+2*(o-7)+t-1>17?"checkboxdivlen":"checkboxdiv",style:["German","Adult","Compas"].indexOf(m.dataname[m.dataNameValue])>-1?"":m.disablestyle,on:{mouseenter:function(e){return m.checkboxMouseEnter(o,t)}}},[m._v(m._s(Object.values(m.evamethod)[18+2*(o-7)+t-1].name))])]):o<=6?e("a-checkbox",{attrs:{value:Object.keys(m.evamethod)[3*(o-1)+t-1]}},[e("div",{class:3*(o-1)+t-1>17?"checkboxdivlen":"checkboxdiv",style:["German","Adult","Compas"].indexOf(m.dataname[m.dataNameValue])>-1?"":m.disablestyle,on:{mouseenter:function(e){return m.checkboxMouseEnter(o,t)}}},[m._v(m._s(Object.values(m.evamethod)[3*(o-1)+t-1].name))])]):m._e()],1)}),m._v(" "),e("transition",{attrs:{name:"fade"}},[e("a-col",{directives:[{name:"show",rawName:"v-show",value:m.methodDesShow[o-1],expression:"methodDesShow[index-1]"}],attrs:{span:24}},[m.rowkey<=6?e("div",{staticClass:"formulaDes"},[e("span",{staticClass:"formula",domProps:{innerHTML:m._s(Object.values(m.evamethod)[3*m.rowkey+m.colkey].formula)}}),m._v(" "),e("span",{staticClass:"formulaDes",domProps:{innerHTML:m._s(Object.values(m.evamethod)[3*m.rowkey+m.colkey].des)}})]):m.rowkey>6?e("div",{staticClass:"formulaDes"},[e("span",{staticClass:"formula",domProps:{innerHTML:m._s(Object.values(m.evamethod)[18+2*(m.rowkey-6)+m.colkey].formula)}}),m._v(" "),e("span",{staticClass:"formulaDes",domProps:{innerHTML:m._s(Object.values(m.evamethod)[18+2*(m.rowkey-6)+m.colkey].des)}})]):m._e()])],1)],2)}),1),m._v(" "),m._l(m.imgEvaMethod,function(o,t){return e("div",{key:t,staticStyle:{"margin-bottom":"16px"}},[e("a-row",{staticStyle:{height:"50px"},attrs:{gutter:16,type:"flex"}},m._l(o,function(a,s){return e("a-col",{key:s,staticClass:"denfenseMethod",attrs:{flex:24/o.length}},[e("a-button",{attrs:{id:"button"+t+s,disabled:!(["Cifar10-S","CelebA"].indexOf(m.dataname[m.dataNameValue])>-1)},on:{click:function(o){return m.changeMethods(t,s)}}},[m._v(m._s(a.name))])],1)}),1),m._v(" "),m.methodHoverIndex==t&&""!==m.methodDescription?e("div",{staticStyle:{padding:"14px 24px","margin-bottom":"16px"}},[m._v(" "+m._s(m.methodDescription)+" ")]):m._e()],1)})],2)])],1)],1)]),m._v(" "),e("div",{directives:[{name:"show",rawName:"v-show",value:m.logflag,expression:"logflag"}]},[e("showLog",{attrs:{percent:m.percent,logtext:m.logtext}})],1),m._v(" "),e("resultDialog",{directives:[{name:"show",rawName:"v-show",value:m.isShowPublish,expression:"isShowPublish"}],attrs:{isShow:m.isShowPublish},on:{"on-close":m.closeDialog}},[e("div",{attrs:{slot:"header"},slot:"header"},[e("div",{staticClass:"dialog_title"},[e("img",{staticClass:"paramIcom",attrs:{src:m.funcDesText.imgpath,alt:m.funcDesText.name}}),m._v(" "),e("h1",[m._v("模型公平性提升结果报告")])])]),m._v(" "),e("div",{staticClass:"dialog_publish_main",attrs:{slot:"main",id:"pdfDom"},slot:"main"},[Object.keys(m.postData).length>0?e("div",{staticStyle:{background:"var(--gray-7, #F2F4F9)",width:"100%",padding:"24px"}},[e("a-row",[e("a-col",{attrs:{span:2}},[e("div",{staticClass:"grid-content-name",staticStyle:{color:"#6C7385"}},[m._v("数据集:")])]),m._v(" "),e("a-col",{attrs:{span:4}},[e("div",{staticClass:"grid-content-value"},[m._v(m._s(m.postData.dataname))])]),m._v(" "),e("a-col",{attrs:{span:2}},[e("div",{staticClass:"grid-content-name",staticStyle:{color:"#6C7385"}},[m._v("模型结构:")])]),m._v(" "),e("a-col",{attrs:{span:4}},[e("div",{staticClass:"grid-content-value"},[m._v(m._s(m.postData.modelname))])]),m._v(" "),e("a-col",{attrs:{span:2}},[e("div",{staticClass:"grid-content-name",staticStyle:{color:"#6C7385"}},[m._v("评估算法:")])]),m._v(" "),e("a-col",{attrs:{span:4}},[e("div",{staticClass:"grid-content-value"},[m._v(m._s(m.defenseShow(m.postData.metrics)))])]),m._v(" "),e("a-col",{attrs:{span:2}},[e("div",{staticClass:"grid-content-name",staticStyle:{color:"#6C7385"}},[m._v("优化算法:")])]),m._v(" "),e("a-col",{attrs:{span:4}},[e("div",{staticClass:"grid-content-value"},[m._v(m._s(m.postData.algorithmname))])])],1)],1):m._e(),m._v(" "),e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"g_score_content"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("数据集公平性提升效果")]),m._v(" "),e("div",{staticClass:"debias_res"},[e("div",{staticClass:"debias_res_score"},[e("img",{staticStyle:{width:"360px","margin-top":"-40px"},attrs:{src:t("9fSZ")}}),m._v(" "),e("p",{staticClass:"g_score"},[m._v(" "+m._s(m.res.score.aft))]),m._v(" "),e("p",{staticClass:"g_score_evaluate"},[m._v(" "+m._s(m.res.score_evaluate.bef))]),m._v(" "),e("p",{staticClass:"debias_state"},[m._v("提升前")])]),m._v(" "),e("div",{staticClass:"to_aft"},[e("img",{staticStyle:{"margin-top":"-40px"},attrs:{src:t("x3Wm")}})]),m._v(" "),e("div",{staticClass:"debias_res_score"},[e("img",{staticStyle:{width:"360px","margin-top":"-40px"},attrs:{src:t("3Vw4")}}),m._v(" "),e("p",{staticClass:"g_score"},[m._v(" "+m._s(m.res.score.aft))]),m._v(" "),e("p",{staticClass:"g_score_evaluate"},[m._v(" "+m._s(m.res.score_evaluate.aft))]),m._v(" "),e("p",{staticClass:"debias_state"},[m._v("提升后")])])])]),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("模型公平性提升后的综合评分为"+m._s(m.res.score.aft)+"，是一个"+m._s(m.res.score_con.aft)+"的模型")]),m._v(" "),e("p",{staticClass:"result_annotation"},[m._v("综合评分计算来源是个体公平性和群体公平性两个维度上的评分")])])]),m._v(" "),["German","Adult","Compas"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("公平性评分详情")]),m._v(" "),e("div",{staticClass:"two_score"},[e("div",{staticClass:"left_score_label"},[e("P",{staticClass:"score_text"},[m._v(m._s(m.res.consistency_score.aft))]),m._v(" "),e("p",{staticClass:"score_lable"},[m._v("个体公平性评估")])],1),m._v(" "),e("div",{staticClass:"center_score_label"},[e("div",{staticClass:"process_bg"},[e("div",{staticClass:"left_pro",style:"width:"+m.res.consistency_score.aft/100*210+"px"})]),m._v(" "),e("div",{staticClass:"process_bg",staticStyle:{"margin-left":"-4px"}},[e("div",{staticClass:"right_pro",style:"width:"+m.res.group_score.aft/100*210+"px"})])]),m._v(" "),e("div",{staticClass:"right_score_label"},[e("P",{staticClass:"score_text"},[m._v(m._s(m.res.group_score.aft))]),m._v(" "),e("p",{staticClass:"score_lable"},[m._v("群体公平性评估")])],1)]),m._v(" "),e("div",{staticClass:"conclusion",staticStyle:{height:"80px"}},[e("div",{staticClass:"score_description"},[e("div",{staticClass:"con_score"},[m._v(m._s(m.res.consistency_score.aft))]),m._v(" "),e("div",{staticClass:"result_text",staticStyle:{"line-height":"24px",display:"inline","font-weight":"500"}},[m._v("模型个体公平性指标为"+m._s(m.res.Consistency.aft))])])]),m._v(" "),e("div",{staticClass:"conclusion",staticStyle:{height:"80px"}},[e("div",{staticClass:"score_description"},[e("div",{staticClass:"con_score"},[m._v(m._s(m.res.group_score.aft))]),m._v(" "),e("div",{staticClass:"result_text",staticStyle:{"line-height":"24px",display:"inline","font-weight":"500"}},[m._v("模型经所选公平性评估算法评估后，综合得分为"+m._s(m.res.group_score.aft))])])])]):m._e(),m._v(" "),["German","Adult","Compas"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"echart_title"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("个体公平性提升得分")]),m._v(" "),e("p",{staticClass:"title_annotation"},[m._v("个体公平性是统计数据集中相似的个体是否有相似的标签或预测结果")])]),m._v(" "),e("div",[e("div",{staticClass:"cons_echart_div"},[e("div",{attrs:{id:"consevaBef"}}),m._v(" "),e("div",{attrs:{id:"consevaAft"}})]),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v(m._s(m.res.consText))]),m._v(" "),e("p",{staticClass:"result_annotation"},[m._v("个体公平性指标越接近1，模型越公平。")])])])]):m._e(),m._v(" "),["German","Adult","Compas"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"echart_title"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("模型群体公平性提升")]),m._v(" "),e("p",{staticClass:"title_annotation"},[m._v("群体公平性是指：根据敏感属性划分各个群体之间在一些目标属性上的差异")])]),m._v(" "),e("div",{staticClass:"group_echarts_div"},m._l(m.senAttrList,function(o,t){return e("div",{key:t,staticClass:"attr_echarts_div"},[e("div",{staticClass:"attr_title_div"},[e("h3",[m._v(m._s(o))]),m._v(" "),e("p",[m._v("敏感属性")])]),m._v(" "),e("div",{staticClass:"group_echart_content"},[e("div",{staticClass:"model_group_echart",attrs:{id:o}})]),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v(m._s(m.res.groupText[o]))])])])}),0)]):m._e(),m._v(" "),["Cifar10-S","CelebA"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div"},[e("div",{staticClass:"echart_title"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("图片数据集提升效果对比图")])]),m._v(" "),e("div",{staticClass:"group_echarts_div"},[e("div",{staticClass:"model_group_echart",attrs:{id:"evaBar"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v(m._s(m.res.groupText.evaBar))])])])]):m._e(),m._v(" "),["German","Adult","Compas"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"echart_title"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("数据集中各群体的占比")])]),m._v(" "),e("div",{attrs:{id:"pro_tree"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("各群体的占比越均匀，数据集越公平")]),m._v(" "),e("p",{staticClass:"result_annotation"},[m._v("子节点面积大小代表占比多少")])])]):m._e(),m._v(" "),["German","Adult","Compas"].indexOf(m.postData.dataname)>-1?e("div",{staticClass:"result_div_notop"},[e("div",{staticClass:"echart_title"},[e("div",{staticClass:"main_top_echarts_con_title"},[m._v("数据集的各属性之间的相关性")]),m._v(" "),e("p",{staticClass:"title_annotation"},[m._v("群体公平性是指：根据敏感属性划分各个群体之间在一些目标属性上的差异")])]),m._v(" "),e("div",{staticClass:"heat_content"},[e("h3",[m._v("互信息系数")]),m._v(" "),e("div",{staticClass:"heat_canvas",style:{height:m.heat_height},attrs:{id:"NMI"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("互信息的值大于等于0，值越大表示两个变量之间的依赖关系越强。互信息为0时，表示两个变量相互独立。但是需要注意的是，互信息值的上限取决于两个变量的熵，因此互信息值本身并不具有直接的对比意义。可以使用归一化互信息（Normalized Mutual Information，NMI）进行归一化处理，将其值映射到0到1之间。")])])]),m._v(" "),e("div",{staticClass:"heat_content"},[e("h3",[m._v("Pearson相关系数")]),m._v(" "),e("div",{staticClass:"heat_canvas",style:{height:m.heat_height},attrs:{id:"person"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("Pearson相关系数的取值范围为-1到1。1表示完全正相关，0表示无关，-1表示完全负相关。")])])]),m._v(" "),e("div",{staticClass:"heat_content"},[e("h3",[m._v("Spearman秩相关系数")]),m._v(" "),e("div",{staticClass:"heat_canvas",style:{height:m.heat_height},attrs:{id:"spearman"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("Spearman秩相关系数的取值范围也为-1到1。1表示完全正单调关系，0表示无单调关系，-1表示完全负单调关系。")])])]),m._v(" "),e("div",{staticClass:"heat_content"},[e("h3",[m._v("Kendall Tau相关系数")]),m._v(" "),e("div",{staticClass:"heat_canvas",style:{height:m.heat_height},attrs:{id:"Kendall"}}),m._v(" "),e("div",{staticClass:"conclusion"},[e("p",{staticClass:"result_text"},[m._v("Kendall Tau相关系数的取值范围也为-1到1。1表示完全正序关系，0表示无序关系，-1表示完全负序关系。")])])])]):m._e(),m._v(" "),e("a-button",{staticStyle:{width:"160px",height:"40px","margin-bottom":"30px","font-size":"18px",color:"white","background-color":"rgb(46, 56, 245)","border-radius":"8px"},on:{click:function(o){return m.getPdf()}}},[m._v("\n                 导出报告内容\n               ")])],1)])],1),m._v(" "),e("a-layout-footer")],1)],1)},staticRenderFns:[]};var k=t("VU/8")(P,Y,!1,function(m){t("Azza")},"data-v-e804c2f8",null);o.default=k.exports},x3Wm:function(m,o){m.exports="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNzgiIGhlaWdodD0iMzUiIHZpZXdCb3g9IjAgMCA3OCAzNSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggaWQ9IlJlY3RhbmdsZSAxODk3IiBkPSJNMCA4LjUzNjU5SDUwVjBMNzggMTcuNUw1MCAzNVYyNi40NjM0SDBWOC41MzY1OVoiIGZpbGw9IiNEM0Q5RTUiLz4KPC9zdmc+Cg=="}});