# via Randomized Smoothing Adversarial Robustness

## train

使用数据增强技术，包括在输入数据中添加高斯噪声，从而提高模型的鲁棒性
从数据集中加载数据，并使用SGD优化器和StepLR学习率调度器进行训练。
在训练过程中，使用数据增强技术，在输入数据中添加高斯噪声，提高模型的鲁棒性。
训练过程中，每个epoch会保存一个checkpoint，包括模型的状态、优化器的状态和当前epoch数。
同时，训练过程中会记录训练和测试的loss和accuracy，并将其写入一个日志文件中。
具体实现细节可以参考train.py文件中的代码。
### 参数含义

```
--dataset：指定数据集的名称，可选值为cifar10、cifar100和imagenet。
--arch：指定网络架构的名称，可选值为resnet20、resnet32、resnet44、resnet56、resnet110和wrn28_10。
--outdir：指定保存模型和训练日志的文件夹路径。
--workers：指定用于数据加载的进程数。
--epochs：指定训练的总epoch数。
--batch：指定batch size的大小。
--lr：指定初始学习率。
--lr_step_size：指定学习率下降的步数。
--gamma：指定学习率下降的倍数。
--momentum：指定SGD优化器的动量参数。
--weight-decay：指定权重衰减的系数。
--noise_sd：指定高斯噪声的标准差{0.0,0.25,0.5,1.0}。
--gpu：指定使用的GPU的编号。
--print-freq：指定训练过程中日志输出的频率。
```

## certify
对数据集上的样本进行平滑分类器的评估。
代码加载一个已经训练好的基分类器，并使用该分类器创建一个平滑分类器。
代码迭代遍历数据集中的每个样本，对每个样本进行平滑分类器的预测，并将结果写入输出文件中。
代码使用Smooth类中的certify方法来计算预测的半径和置信度，并将结果写入输出文件中。


### 参数含义
```
--dataset：数据集名称。
--base_classifier：基分类器的路径。
--sigma：噪声超参数。
--outfile：输出文件路径。
--batch：批量大小。
--skip：跳过的样本数。
--max：最大样本数。
--split：数据集划分，可选值为“train”或“test”。
--N0：用于计算置信度的初始样本数。
--N：用于计算置信度的总样本数。
--alpha：置信度的失败概率。
```

## predict

在给定数据集上运行基础分类器并进行预测的脚本。

加载基础分类器并创建平滑分类器。
输出文件并迭代数据集中的每个样本。
只对每个 args.skip 个样本进行认证，并在 args.max 个样本后停止。
对于每个样本，将其输入到平滑分类器中进行预测，并记录预测结果、是否正确以及所用时间。
将这些信息写入输出文件中。



### 参数含义
```
--dataset：数据集名称。
--base_classifier：基础分类器的路径。
--sigma：噪声超参数。
--outfile：输出文件名。
--batch：批量大小。
--skip：每隔多少个样本进行认证。
--max：最多认证多少个样本。
--split：使用训练集还是测试集。
--N：用于计算置信区间的样本数。
--alpha：失败概率。
```


## visualize
可视化噪声图像
使用 get_dataset 函数从给定的数据集名称和拆分中获取数据集，然后从该数据集中获取给定索引的图像。
使用 torch.randn_like 函数生成与图像相同形状的噪声张量。
对于每个给定的噪声标准差，使用 torch.clamp 函数将噪声应用于图像，并将结果保存为 PNG 文件。
保存的文件名包括图像索引和噪声标准差的整数值。

### 参数含义
```
--dataset：数据集名称，必须是 DATASETS 中的一个。
--outdir：输出目录的路径。
--idx：要可视化的图像在数据集中的索引。
--noise_sds：要应用于图像的噪声标准差的列表。
--split：可选参数，指定要使用的数据集拆分，可以是 "train" 或 "test"。默认为 "test"。
```