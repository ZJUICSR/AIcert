{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8ee1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' # 下面老是报错 shape 不一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0f21b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagenet_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_765217/1470973242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimagenet_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvgg_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0madv_cleverhans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imagenet_labels'"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "from imagenet_labels import *\n",
    "from vgg_model import *\n",
    "from adv_cleverhans import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#data_transform = transforms.Compose(\n",
    "#    [transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])# 把[0,1]归一化到[-1,1]\n",
    "\n",
    "#train_dataset = datasets.CIFAR10(root='./data', train=True,download=False, transform=data_transform)\n",
    "val_dataset = datasets.CIFAR10(root='../dataset/data', train=False,download=False, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "model = VggNet(num_classes=10)\n",
    "model.load_state_dict((torch.load('../AT_vgg16_cifar10/checkpoint/cifar-10_std/checkpoint_76000.pth')))#评估普通模型-干净样本准确率\n",
    "model = model.to(device).eval()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "    'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#加载测试数据集\n",
    "images=torch.load('testdata_2560clean_2560adv_fgsm_cifar10.pt')\n",
    "labels=torch.load('testlabel_2560clean_2560adv_fgsm_cifar10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e30b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5120])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7974dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_through_model(model, prefix=''):\n",
    "    for name, module in model.named_children():\n",
    "        path = '{}/{}'.format(prefix, name)\n",
    "        if (isinstance(module, nn.Conv1d)\n",
    "            or isinstance(module, nn.Conv2d)\n",
    "            or isinstance(module, nn.Linear)): # test for dataset\n",
    "            yield (path, name, module)\n",
    "        else:\n",
    "            yield from step_through_model(module, path)\n",
    "\n",
    "def get_model_layers(model, cross_section_size=0):\n",
    "    layer_dict = {}\n",
    "    i = 0\n",
    "    for (path, name, module) in step_through_model(model):\n",
    "        layer_dict[str(i) + path] = module\n",
    "        i += 1\n",
    "    if cross_section_size > 0:\n",
    "        target_layers = list(layer_dict)[0::cross_section_size] \n",
    "        layer_dict = { target_layer: layer_dict[target_layer] for target_layer in target_layers }\n",
    "    return layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101730ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0/features/features/0': Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '1/features/features/3': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '2/features/features/7': Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '3/features/features/10': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '4/features/features/14': Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '5/features/features/17': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '6/features/features/20': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '7/features/features/24': Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '8/features/features/27': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '9/features/features/30': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '10/features/features/34': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '11/features/features/37': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '12/features/features/40': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " '13/classifier/0': Linear(in_features=25088, out_features=512, bias=True),\n",
       " '14/classifier/3': Linear(in_features=512, out_features=128, bias=True),\n",
       " '15/classifier/6': Linear(in_features=128, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dict = get_model_layers(model)\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5026a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output_sizes(model, data, layer_name=None):   \n",
    "    output_sizes = {}\n",
    "    hooks = []  \n",
    "    \n",
    "    layer_dict = get_model_layers(model)\n",
    " \n",
    "    def hook(module, input, output):\n",
    "        module_idx = len(output_sizes)\n",
    "        m_key = list(layer_dict)[module_idx]\n",
    "        output_sizes[m_key] = list(output.size()[1:])      \n",
    "    \n",
    "    for name, module in layer_dict.items():\n",
    "        hooks.append(module.register_forward_hook(hook))\n",
    "    \n",
    "    try:\n",
    "        model(data[:1])  \n",
    "    finally:\n",
    "        for h in hooks:\n",
    "            h.remove() \n",
    "            \n",
    "    return output_sizes\n",
    "\n",
    "def get_init_activate_dict(model, data, init_value=False, layer_name=None): \n",
    "    output_sizes = get_layer_output_sizes(model, data, layer_name)       \n",
    "    model_layer_dict = {}  \n",
    "    for layer, output_size in output_sizes.items():\n",
    "        for index in range(np.prod(output_size)):\n",
    "            # since we only care about post-activation outputs\n",
    "            model_layer_dict[(layer, index)] = init_value\n",
    "    neurons_activate_dict=[]\n",
    "    for i in range(len(data)):\n",
    "        neurons_activate_dict.append(model_layer_dict)\n",
    "    return neurons_activate_dict\n",
    "\n",
    "def scale(out, rmax=1, rmin=0):\n",
    "    output_std = (out - out.min()) / (out.max() - out.min())\n",
    "    output_scaled = output_std * (rmax - rmin) + rmin\n",
    "    return output_scaled\n",
    "\n",
    "def extract_outputs(model, data, module, force_relu=True):\n",
    "    outputs = []      \n",
    "    def hook(module, input, output):\n",
    "        if force_relu:\n",
    "            outputs.append(torch.relu(output))   \n",
    "        else:\n",
    "            outputs.append(output)\n",
    "    handle = module.register_forward_hook(hook)     \n",
    "    model(data)\n",
    "    handle.remove()\n",
    "    return torch.stack(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b71e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=images[:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test=labels[:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1a544d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 26.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_num=256 #样本个数\n",
    "\n",
    "neurons_activate_dict=torch.zeros(sample_num,1).to(device)\n",
    "layer_dict = get_model_layers(model) \n",
    "for layer, module in tqdm(layer_dict.items()): \n",
    "    outputs = torch.squeeze(extract_outputs(model, data.to(device), module))\n",
    "    scaled_outputs = scale(outputs)\n",
    "    sample_layer_outputs=scaled_outputs.view(sample_num,-1)  #sample_layer_outputs表示所有样本的某层输出--神经元激活值\n",
    "    neurons_activate_dict=torch.cat([neurons_activate_dict, sample_layer_outputs], dim=1)\n",
    "    #print(neurons_activate_dict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1015f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0260, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0961, 0.0837,  ..., 0.0000, 0.4774, 0.0462],\n",
       "        [0.0000, 0.0829, 0.0770,  ..., 0.0000, 0.5527, 0.0465],\n",
       "        ...,\n",
       "        [0.0000, 0.0406, 0.0112,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0806, 0.0917,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0476, 0.0560,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_activate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e42b12e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncovered_neurons=0\\ntotal_neurons=0\\ncovered_dict=torch.zeros([277131]).to(device)\\n\\nfor sample_index, sample_activation in enumerate(neurons_activate_dict):\\n    #print(sample_index)\\n    covered_dict+=sample_activation\\n    covered_dict=torch.gt(covered_dict,0)\\n    covered_neurons=torch.sum(covered_dict)\\n    covered_dict=covered_dict.float()\\n    total_neurons=sample_activation.size(0)\\n    coverage= covered_neurons / float(total_neurons)\\n    print(sample_index,coverage.item(),covered_neurons.item(),total_neurons)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "covered_neurons=0\n",
    "total_neurons=0\n",
    "covered_dict=torch.zeros([277131]).to(device)\n",
    "\n",
    "for sample_index, sample_activation in enumerate(neurons_activate_dict):\n",
    "    #print(sample_index)\n",
    "    covered_dict+=sample_activation\n",
    "    covered_dict=torch.gt(covered_dict,0)\n",
    "    covered_neurons=torch.sum(covered_dict)\n",
    "    covered_dict=covered_dict.float()\n",
    "    total_neurons=sample_activation.size(0)\n",
    "    coverage= covered_neurons / float(total_neurons)\n",
    "    print(sample_index,coverage.item(),covered_neurons.item(),total_neurons)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23fd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_activate_dict.shape\n",
    "\n",
    "neuron_activate=neurons_activate_dict.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f29af1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_activate.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbb0bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照样本的神经元覆盖率进行排序\n",
    "class NBC():\n",
    "    def __init__(self,model,test,neuron_act,std=0):#model模型，test测试用例集，t神经元激活门限\n",
    "        self.test = test\n",
    "        self.std=std\n",
    "        self.lst = []\n",
    "        self.neuron_activate = neuron_act\n",
    "        index_lst = []\n",
    "\n",
    "        self.neuron_num = neuron_activate.shape[1]\n",
    "        self.lst = list(zip(index_lst, self.lst))\n",
    "        \n",
    "        self.upper=np.mean(np.max(self.neuron_activate, axis=1) + std * np.std(self.neuron_activate, axis=1))\n",
    "        self.lower=np.mean(np.min(self.neuron_activate, axis=1) - std * np.std(self.neuron_activate, axis=1))\n",
    "\n",
    "    def fit(self):\n",
    "        neuron_activate = 0\n",
    "        for index in range(len(self.neuron_activate)):\n",
    "            neu=self.neuron_activate[index]\n",
    "            neuron_activate += np.sum(np.sum(neu > self.upper, axis=0) > 0)\n",
    "            neuron_activate += np.sum(np.sum(neu < self.lower, axis=0) > 0)\n",
    "        return neuron_activate / float(self.neuron_num)\n",
    "\n",
    "    def rank_fast(self):\n",
    "\n",
    "        # 注释:类似于贪心算法\n",
    "        # 思想,先随机选一个,记录激活的神经元,在顺序遍历所有的例子,找到一个和原有例子放在一起后\n",
    "        # 可以激活最多个数神经元的例子,找到后就放在数组里记录它的索引\n",
    "        # 直到没有神经元找得到或者全找完了为止\n",
    "        upper = (self.neuron_activate > self.upper)  # upper是一个TrueFalse 矩阵,shape(用例数,神经元数)\n",
    "        lower = (self.neuron_activate < self.lower)  # lower是一个TrueFalse 矩阵,shape(用例数,神经元数)\n",
    "        subset = []  # 存放最终的选择序列\n",
    "        lst = list(range(len(self.test)))  # 存放所有的测试集的索引\n",
    "        initial = np.random.choice(range(len(self.test)))  ## initial是随机选择了一个测试用例的下标\n",
    "        lst.remove(initial)\n",
    "        subset.append(initial)  # 将下标从lst移除,添加到subset中  下次就不会遍历到它\n",
    "        max_cover_num = np.sum(upper[initial])+np.sum(lower[initial])  # 统计激活了的神经元的个数\n",
    "        cover_last_1 = upper[initial]  # 选取了第x个测试用例对应的全部神经元的激活状态\n",
    "        cover_last_2 = lower[initial]  # 选取了第x个测试用例对应的全部神经元的激活状态\n",
    "        # 遍历剩下的用例\n",
    "        while True:\n",
    "            flag = False\n",
    "            for index in tqdm(lst):\n",
    "                # cover_last_1 定义过,就是第x个的用例的神经元激活状态,\n",
    "                # upper[index] 是第i个用例的神经元激活状态\n",
    "                # 两者求异或,意味着两者中对应神经元位置有一个激活则算作激活\n",
    "                temp1 = np.bitwise_or(cover_last_1, upper[index])\n",
    "                temp2 = np.bitwise_or(cover_last_2, lower[index])\n",
    "                cover1 = np.sum(temp1)  # 求激活了的神经元数量\n",
    "                cover1 += np.sum(temp2) # 求激活了的神经元数量\n",
    "                if cover1 > max_cover_num:  # 如果激活了的数量大于之前的神经元激活数量\n",
    "                    max_cover_num = cover1  # 将最大激活数量改为新值\n",
    "                    max_index = index  # 记录下来当前例子的索引\n",
    "                    flag = True  # 继续循环\n",
    "                    max_cover1 = temp1  # 添加了新用例之后的神经元激活状态\n",
    "                    max_cover2 = temp2  # 添加了新用例之后的神经元激活状态\n",
    "            # 至此结束,每次选择了一个新的用例,保证此时激活了的神经元最多,并添加进数组\n",
    "            if not flag or len(lst) == 1:\n",
    "                break\n",
    "            # 如果找到了新的用例,或者还有1个用例以上,就继续循环  #找不到用例意味着满足了最大覆盖,到1个用例意味着全选完了\n",
    "            lst.remove(max_index)  # 移除最大的例子的索引\n",
    "            subset.append(max_index)  # 添加进来\n",
    "            cover_last_1 = max_cover1  # 赋值\n",
    "            cover_last_2 = max_cover2  # 赋值\n",
    "            print(max_cover_num)\n",
    "        return np.append(subset,lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d071c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568755\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 1444.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 1426.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 253/253 [00:00<00:00, 1404.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 252/252 [00:00<00:00, 1415.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 251/251 [00:00<00:00, 1422.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 1434.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 249/249 [00:00<00:00, 1421.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 1433.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 247/247 [00:00<00:00, 1435.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 246/246 [00:00<00:00, 1445.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 245/245 [00:00<00:00, 1433.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 244/244 [00:00<00:00, 1448.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 243/243 [00:00<00:00, 1441.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 1444.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 241/241 [00:00<00:00, 1448.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 240/240 [00:00<00:00, 1448.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 1436.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 238/238 [00:00<00:00, 1418.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 237/237 [00:00<00:00, 1429.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 236/236 [00:00<00:00, 1442.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 235/235 [00:00<00:00, 1435.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 234/234 [00:00<00:00, 1437.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 233/233 [00:00<00:00, 1442.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 232/232 [00:00<00:00, 1448.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 231/231 [00:00<00:00, 1433.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 230/230 [00:00<00:00, 1443.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 1437.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 228/228 [00:00<00:00, 1441.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 227/227 [00:00<00:00, 1440.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 226/226 [00:00<00:00, 1431.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 225/225 [00:00<00:00, 1406.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 224/224 [00:00<00:00, 1427.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 223/223 [00:00<00:00, 1425.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 222/222 [00:00<00:00, 1407.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 221/221 [00:00<00:00, 1035.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 220/220 [00:00<00:00, 1353.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 219/219 [00:00<00:00, 1447.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 218/218 [00:00<00:00, 1444.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 217/217 [00:00<00:00, 1455.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 216/216 [00:00<00:00, 1453.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 1448.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 214/214 [00:00<00:00, 1446.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 213/213 [00:00<00:00, 1423.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 212/212 [00:00<00:00, 1443.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 211/211 [00:00<00:00, 1444.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 1443.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 209/209 [00:00<00:00, 1450.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 208/208 [00:00<00:00, 1450.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 207/207 [00:00<00:00, 1444.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 206/206 [00:00<00:00, 1434.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 205/205 [00:00<00:00, 1438.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 204/204 [00:00<00:00, 1428.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 203/203 [00:00<00:00, 1438.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 202/202 [00:00<00:00, 1434.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 201/201 [00:00<00:00, 1436.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 1444.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 199/199 [00:00<00:00, 1430.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 198/198 [00:00<00:00, 1431.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 197/197 [00:00<00:00, 1450.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 196/196 [00:00<00:00, 1444.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 195/195 [00:00<00:00, 1434.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 194/194 [00:00<00:00, 1442.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 193/193 [00:00<00:00, 1442.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 192/192 [00:00<00:00, 1429.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 191/191 [00:00<00:00, 1422.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 1428.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 189/189 [00:00<00:00, 1431.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 1433.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 187/187 [00:00<00:00, 1438.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 186/186 [00:00<00:00, 1436.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 185/185 [00:00<00:00, 1413.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 184/184 [00:00<00:00, 1423.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 183/183 [00:00<00:00, 1441.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 182/182 [00:00<00:00, 1171.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 181/181 [00:00<00:00, 1316.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 180/180 [00:00<00:00, 1436.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 179/179 [00:00<00:00, 1438.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 178/178 [00:00<00:00, 1432.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 177/177 [00:00<00:00, 1433.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 1431.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 175/175 [00:00<00:00, 1430.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 174/174 [00:00<00:00, 1441.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 1446.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 172/172 [00:00<00:00, 1431.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 171/171 [00:00<00:00, 1437.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 170/170 [00:00<00:00, 1431.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 169/169 [00:00<00:00, 1432.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 168/168 [00:00<00:00, 1424.43it/s]\n",
      "/home/zxliang/anaconda3/envs/logic/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "# 可以贪心排\n",
    "# 可以单个样本比较排\n",
    "# 0 0.5 1\n",
    "ac = NBC(model,data.to(device),neuron_activate,0)\n",
    "rate = ac.fit()\n",
    "start = time.time()\n",
    "rank_lst = ac.rank_fast()\n",
    "end = time.time()\n",
    "rank_lst_time = end-start\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "pred_test = model(data.to(device)).argmax(dim=1).cpu().numpy()\n",
    "true_test=true_test.cpu().numpy()\n",
    "df['right'] = (pred_test == true_test).astype('int')\n",
    "df['cam'] = 0\n",
    "df['cam'].loc[rank_lst] = list(range(1, len(rank_lst) + 1))\n",
    "df['cam_time'] = rank_lst_time\n",
    "df['rate'] = rate\n",
    "df['ctm'] = 0\n",
    "df['ctm'].loc[rank_lst] = list(range(1, len(rank_lst) + 1))\n",
    "df['ctm_time'] = rank_lst_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f96e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./all_output/output_cifar/{}/{}_nbc_t_{}.csv'.format('vgg16', 'cifar', 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dcd4f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ab373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
