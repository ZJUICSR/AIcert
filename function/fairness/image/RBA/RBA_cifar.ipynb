{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "GRAYSCALE = 0\n",
    "COLOR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimize_potentials_given_known_domain():\n",
    "    \"\"\"Given a set of network outputs on a test set, updates potentials to reduce bias.\n",
    "    \n",
    "    Args:\n",
    "      input_potentials: A float64 numpy array with shape (test_set_size, class_count).\n",
    "        Contains the network outputs on each test example, for a single class prediction\n",
    "        with known domain.\n",
    "      gt_domain: An int32 numpy array with shape (test_set_size,). The ground truth\n",
    "        domain. Used to do the optimization.\n",
    "      gt_class: An int32 numpy array with shape (test_set_size,). The ground truth\n",
    "        class label. Used only to compute accuracy.\n",
    "      training_set_frequencies: A float32 numpy array with shape (test_set_size, class_count).\n",
    "        The relative frequencies of the training set classes given each example's known domain.\n",
    "        \n",
    "    Returns:\n",
    "      output_potentials: A float64 numpy array with shape (test_set_size, class_count).\n",
    "        Contains the optimized network potentials that are the result of the optimization.\n",
    "      output_predictions: An int32 numpy array with shape (test_set_size,). Contains\n",
    "        the final network predictions (i.e. just an argmax over the potentials).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_potentials, gt_class, gt_domain, training_set_frequencies, lr,\n",
    "                       margin, apply_prior_shift, inputs_are_activations, method_name,\n",
    "                       target_domain_ratios, domain_labels, verbosity=2, total_epochs=100):\n",
    "        \n",
    "        self.test_set_size = gt_class.shape[0]\n",
    "        self.class_count = input_potentials.shape[1]\n",
    "        self.input_potentials = input_potentials\n",
    "        self.gt_class = gt_class\n",
    "        self.gt_domain = gt_domain\n",
    "        self.training_set_frequencies = training_set_frequencies\n",
    "        self.lr = lr\n",
    "        self.margin = margin\n",
    "        self.apply_prior_shift = apply_prior_shift\n",
    "        self.inputs_are_activations = inputs_are_activations\n",
    "        self.method_name = method_name\n",
    "        self.target_domain_ratios = target_domain_ratios\n",
    "        self.domain_labels = domain_labels\n",
    "        self.verbosity = verbosity\n",
    "        self.total_epochs = total_epochs\n",
    "    \n",
    "    def cifar_compute_accuracy(self, potentials, eval_dataset='balanced'):\n",
    "        \"\"\"Computes the accuracy from a set of potentials.\"\"\"\n",
    "        total_correct_class_count = 0\n",
    "        predicted_class = self.cifar_inference(potentials)\n",
    "        is_correct = np.equal(predicted_class, self.gt_class).astype(np.float64)\n",
    "        if eval_dataset == 'gray':\n",
    "            return np.mean(is_correct[self.gt_domain == GRAYSCALE])\n",
    "        elif eval_dataset == 'color':\n",
    "            return np.mean(is_correct[self.gt_domain == COLOR])\n",
    "        elif eval_dataset == 'balanced':\n",
    "            return np.mean(is_correct)\n",
    "        elif eval_dataset == 'per_class_per_domain':\n",
    "            class_count = int(np.max(self.gt_class)) + 1\n",
    "            class_accs = np.zeros((class_count,))\n",
    "            for i in range(class_count):\n",
    "                i_grayscale_examples = (self.gt_class == i) & (self.gt_domain == GRAYSCALE)\n",
    "                if np.any(i_grayscale_examples):\n",
    "                    grayscale_acc = np.mean(is_correct[i_grayscale_examples])\n",
    "                else:\n",
    "                    grayscale_acc = 1.0\n",
    "                i_color_examples = (self.gt_class == i) & (self.gt_domain == COLOR)\n",
    "                if np.any(i_color_examples):\n",
    "                    color_acc = np.mean(is_correct[i_color_examples])\n",
    "                else:\n",
    "                    color_acc = 1.0\n",
    "                class_accs[i] = (grayscale_acc + color_acc) / 2.0\n",
    "            return np.mean(class_accs)\n",
    "        assert False\n",
    "        \n",
    "    def cifar_compute_bias(self, potentials):\n",
    "        predicted_class = self.cifar_inference(potentials)\n",
    "        count_per_class = self.cifar_count_domain_incidence_from_gt(predicted_class)\n",
    "        bias_towards_grayscale = count_per_class[:, GRAYSCALE] / np.maximum(np.sum(count_per_class, axis=1), 1.0)\n",
    "        total_bias = np.abs(bias_towards_grayscale - 0.5)\n",
    "        mean_class_bias = np.mean(total_bias)\n",
    "        return mean_class_bias\n",
    "    \n",
    "    def cifar_count_domain_incidence_from_gt(self, predicted_classes):\n",
    "        \"\"\"Computes a dictionary mapping class_idx:[grayscale_count, color_count]\n",
    "        \n",
    "        This function uses the ground truth domain label to do the count.\n",
    "        \n",
    "        Args:\n",
    "          predicted_classes: An int32 numpy array with shape (test_set_size,). The\n",
    "            class labels.\n",
    "        \"\"\"\n",
    "        count_per_class = np.zeros((self.class_count, 2), dtype=np.float64)\n",
    "        for i in range(self.test_set_size):\n",
    "            predicted_class = int(predicted_classes[i])\n",
    "            count_per_class[predicted_class][int(self.gt_domain[i])] += 1\n",
    "        return count_per_class\n",
    "    \n",
    "    def cifar_inference(self, potentials):\n",
    "        \"\"\"Computes the current class prediction from a set of potentials.\n",
    "        \n",
    "        Args:\n",
    "          potentials: A float64 numpy array of shape (test_set_size, class_count).\"\"\"\n",
    "        if self.inputs_are_activations:\n",
    "            potentials = np.exp(potentials)\n",
    "        if self.apply_prior_shift:\n",
    "            probabilities = np.divide(potentials, self.training_set_frequencies)\n",
    "            return np.argmax(probabilities, axis=1)\n",
    "        predicted_classes = np.argmax(potentials, axis=1)\n",
    "        return predicted_classes\n",
    "    \n",
    "    def cifar_generate_constraints(self, margin):\n",
    "        constraints = np.zeros((self.class_count, 2, 2))\n",
    "        constraints[:, 0, 0] = self.target_domain_ratios - 1 - self.margin\n",
    "        constraints[:, 0, 1] = self.target_domain_ratios - self.margin\n",
    "        constraints[:, 1, 0] = 1 - (self.margin + self.target_domain_ratios)\n",
    "        constraints[:, 1, 1] = -(self.margin + self.target_domain_ratios)\n",
    "        return constraints\n",
    "    \n",
    "    def optimize(self, input_potentials):\n",
    "        if self.verbosity >= 1:\n",
    "            initial_accuracy = self.cifar_compute_accuracy(input_potentials, 'balanced')\n",
    "            initial_bias = self.cifar_compute_bias(input_potentials)\n",
    "            name_in = ('Settings \"%s\", before opt.' % self.method_name).ljust(85)\n",
    "            print('%s Acc. %f%%. Bias %f' % (name_in, 100*initial_accuracy, initial_bias))\n",
    "            initial_gray_accuracy = self.cifar_compute_accuracy(input_potentials, 'gray')\n",
    "            initial_color_accuracy = self.cifar_compute_accuracy(input_potentials, 'color')\n",
    "            initial_mcd_accuracy = self.cifar_compute_accuracy(input_potentials, 'per_class_per_domain')\n",
    "            print('%s Acc: %f%%. %s Acc: %f%%. Mean Per-C Per-D Acc: %f%%' % (\n",
    "                self.domain_labels[0], 100*(initial_gray_accuracy), self.domain_labels[1],\n",
    "                100*(initial_color_accuracy), 100*initial_mcd_accuracy))\n",
    "        if self.verbosity >= 2:\n",
    "            initial_accuracy = self.cifar_compute_accuracy(input_potentials, 'balanced')\n",
    "            print('Pre optimization accuracy: %f%%' % (100.0*initial_accuracy))\n",
    "        lambdas = np.zeros((self.class_count, 2), dtype=np.float64)\n",
    "        current_potentials = input_potentials.copy()\n",
    "        constraints = self.cifar_generate_constraints(self.margin)\n",
    "        initial_predictions = self.cifar_inference(input_potentials)\n",
    "        for epoch in range(self.total_epochs):\n",
    "            violated_constraint_count = 0\n",
    "            error = np.zeros((self.class_count, 2), dtype=np.float64)\n",
    "\n",
    "            class_prediction = self.cifar_inference(current_potentials)\n",
    "            count_per_class = self.cifar_count_domain_incidence_from_gt(class_prediction)\n",
    "            count_per_class = np.reshape(count_per_class, [self.class_count, 1, 2])\n",
    "            constraint_delta = np.sum(constraints * count_per_class, axis=2)\n",
    "            lambdas += self.lr * constraint_delta\n",
    "            error += constraint_delta\n",
    "            count_per_class = np.reshape(count_per_class, [self.class_count, 2])\n",
    "\n",
    "            lambdas = np.maximum(lambdas, 0)\n",
    "            violated_constraint_count = np.count_nonzero(error > 0)\n",
    "            current_potentials = input_potentials.copy()\n",
    "\n",
    "            for i in range(len(current_potentials)):\n",
    "                domain_idx = self.gt_domain[i]\n",
    "                class_idx = class_prediction[i]\n",
    "                constraint_idx = class_idx\n",
    "                current_potentials[i][class_idx] -= lambdas[constraint_idx][0] * constraints[constraint_idx][0][domain_idx]\n",
    "                current_potentials[i][class_idx] -= lambdas[constraint_idx][1] * constraints[constraint_idx][1][domain_idx]\n",
    "\n",
    "            if (epoch % 10 == 0 or epoch == self.total_epochs-1) and self.verbosity >= 2:\n",
    "                print('Finished %i-th Epoch.' % epoch)\n",
    "                ratios = count_per_class[:, GRAYSCALE] / np.maximum((count_per_class[:, GRAYSCALE] + count_per_class[:, COLOR]), 1.0)\n",
    "                bias = np.abs(ratios - 0.5)\n",
    "                mean_bias = np.mean(bias)\n",
    "                print('\\tMean Bias: %0.4f' % mean_bias)\n",
    "                constraint_count = len(constraints)\n",
    "                print('\\tConstraint Satisfaction: %i/%i' % (constraint_count-violated_constraint_count, constraint_count))\n",
    "                current_accuracy = self.cifar_compute_accuracy(current_potentials, 'balanced')\n",
    "                total_flipped_predictions = np.count_nonzero(self.cifar_inference(current_potentials) != initial_predictions)\n",
    "                print('\\tTotal Flipped Predictions: %i' % total_flipped_predictions)\n",
    "                print('\\tCurrent Accuracy: %0.2f%%' % (100.0*current_accuracy))\n",
    "\n",
    "            if violated_constraint_count == 0:\n",
    "                break\n",
    "        if self.verbosity >= 1:\n",
    "            final_accuracy = self.cifar_compute_accuracy(current_potentials, 'balanced')\n",
    "            final_bias = self.cifar_compute_bias(current_potentials)\n",
    "            name_in = ('Settings \"%s\", after opt' % self.method_name).ljust(85)\n",
    "            print('%s Acc. %f%%. Bias %f' % (name_in, 100*(final_accuracy), (final_bias)))\n",
    "            final_gray_accuracy = self.cifar_compute_accuracy(current_potentials, 'gray')\n",
    "            final_color_accuracy = self.cifar_compute_accuracy(current_potentials, 'color')\n",
    "            final_mcd_accuracy = self.cifar_compute_accuracy(current_potentials, 'per_class_per_domain')\n",
    "            print('%s Acc: %f%%. %s Acc: %f%%. Mean Per-C Per-D Acc: %f%%' % (\n",
    "                self.domain_labels[0], 100*(final_gray_accuracy), self.domain_labels[1],\n",
    "                100*(final_color_accuracy), 100*final_mcd_accuracy))\n",
    "            \n",
    "        print('Accuracy change: {}, bias change: {}'.format(final_accuracy-initial_accuracy, final_bias-initial_bias))\n",
    "        return current_potentials, self.cifar_inference(current_potentials)\n",
    "    \n",
    "def run(hparams, data):\n",
    "    optimize_probabilities = hparams['optimize_probabilities']\n",
    "    reduction_method = hparams['reduction']\n",
    "    apply_prior_shift = hparams['prior_shift']\n",
    "    train_time_frequencies = data['train_time_frequencies']\n",
    "    domain_targets = data['domain_targets']\n",
    "    twon_activations = data['twon_activations']\n",
    "    target_domain_ratios = data['target_domain_ratios']\n",
    "    domain_labels = data['domain_labels']\n",
    "    expected_class_count = len(train_time_frequencies)//2\n",
    "\n",
    "    selected_outputs = []\n",
    "    selected_train_probabilities = []\n",
    "    # Cut down to relevant N values by subsituting in known domain:\n",
    "    for i in range(domain_targets.shape[0]):\n",
    "        cur_domain = domain_targets[i]\n",
    "        if cur_domain == GRAYSCALE:   \n",
    "            selected_train_probabilities.append(train_time_frequencies[expected_class_count:])\n",
    "        elif cur_domain == COLOR:   \n",
    "            selected_train_probabilities.append(train_time_frequencies[:expected_class_count])\n",
    "        else:\n",
    "            assert False\n",
    "    train_probabilities = np.stack(selected_train_probabilities, axis=0)\n",
    "\n",
    "    twon_activations = np.exp(twon_activations)\n",
    "    if apply_prior_shift:\n",
    "        twon_activations /= train_time_frequencies\n",
    "        # We already applied prior shift:\n",
    "        apply_prior_shift = False\n",
    "        \n",
    "    if reduction_method == 'sum':\n",
    "        outputs = twon_activations[:, :expected_class_count] + twon_activations[:, expected_class_count:]\n",
    "\n",
    "    if reduction_method == 'condition':\n",
    "        for i in range(twon_activations.shape[0]):\n",
    "            cur_domain = domain_targets[i]\n",
    "            if cur_domain == GRAYSCALE:\n",
    "                selected_outputs.append(twon_activations[i, expected_class_count:])\n",
    "            elif cur_domain == COLOR:\n",
    "                selected_outputs.append(twon_activations[i, :expected_class_count])\n",
    "            else:\n",
    "                assert False\n",
    "        outputs = np.stack(selected_outputs, axis=0)\n",
    "        \n",
    "    margin = 0.05\n",
    "    lr = hparams['lr']\n",
    "    input_potentials = outputs\n",
    "    \n",
    "    optimization_str = 'optimize on probabilities' if hparams['optimize_probabilities'] else 'optimize on outputs'\n",
    "    if hparams['optimize_probabilities'] and hparams['reduction'] == 'sum':\n",
    "        reduction_str = 'sum probabilities'\n",
    "    elif hparams['optimize_probabilities'] and hparams['reduction'] == 'condition':\n",
    "        reduction_str = 'condition on d0'\n",
    "    elif not hparams['optimize_probabilities'] and hparams['reduction'] =='sum':\n",
    "        reduction_str = 'sum outputs'\n",
    "    elif not hparams['optimize_probabilities'] and hparams['reduction'] == 'condition':\n",
    "        reduction_str = 'condition on d0'\n",
    "    else:\n",
    "        assert False\n",
    "    prior_shift_str = 'prior shift' if hparams['prior_shift'] else 'no prior shift'\n",
    "    method_str = '%s, %s, %s' % (reduction_str, optimization_str, prior_shift_str)\n",
    "            \n",
    "    optimizer = optimize_potentials_given_known_domain(input_potentials=input_potentials,\n",
    "                                                       gt_domain=domain_targets,\n",
    "                                                       gt_class=class_targets,\n",
    "                                                       training_set_frequencies=train_probabilities,\n",
    "                                                       lr=lr,\n",
    "                                                       margin=margin,\n",
    "                                                       apply_prior_shift=apply_prior_shift,\n",
    "                                                       inputs_are_activations=(not optimize_probabilities),\n",
    "                                                       method_name=method_str,\n",
    "                                                       target_domain_ratios=target_domain_ratios,\n",
    "                                                       domain_labels=domain_labels,\n",
    "                                                       verbosity=hparams['verbosity'],\n",
    "                                                       total_epochs=hparams['total_epochs'])\n",
    "    \n",
    "    output_potentials, output_predictions = optimizer.optimize(input_potentials)\n",
    "    return output_potentials, output_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the corresponding result path\n",
    "color_result_path = '../record/cifar-s_domain_discriminative/cifar-s_domain_discriminative_e1/test_color_result.pkl'\n",
    "gray_result_path = '../record/cifar-s_domain_discriminative/cifar-s_domain_discriminative_e1/test_gray_result.pkl'\n",
    "with open(color_result_path, 'rb') as f:\n",
    "    color_result = pickle.load(f)\n",
    "with open(gray_result_path, 'rb') as f:\n",
    "    gray_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cifar_test_labels', 'rb') as f:\n",
    "    test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_frequencies = np.array([0.005, 0.095, 0.005, 0.095, 0.005, \n",
    "                                   0.095, 0.005, 0.095, 0.005, 0.095,\n",
    "                                   0.095, 0.005, 0.095, 0.005, 0.095,\n",
    "                                   0.005, 0.095, 0.005, 0.095, 0.005], dtype=np.float64) \n",
    "\n",
    "domain_zeros = np.zeros([10000,], dtype=np.int32)\n",
    "domain_ones = np.ones([10000,], dtype=np.int32)\n",
    "domain_targets = np.concatenate([domain_zeros, domain_ones], axis=0)\n",
    "\n",
    "twon_gray_outs = color_result['outputs']\n",
    "twon_color_outs = gray_result['outputs']\n",
    "\n",
    "twon_activations = np.concatenate([twon_gray_outs, twon_color_outs], axis=0)\n",
    "\n",
    "class_targets = np.array(test_labels + test_labels)\n",
    "target_domain_ratios = 0.5 * np.ones((10,))\n",
    "domain_labels = ['Gray', 'Color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train_time_frequencies': train_time_frequencies, 'domain_targets': domain_targets,\n",
    "        'twon_activations': twon_activations, 'target_domain_ratios': target_domain_ratios,\n",
    "        'domain_labels': domain_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum without prior shift\n",
    "hparams = {'optimize_probabilities': True, 'reduction': 'sum', 'prior_shift': False, 'lr': 3,\n",
    "           'total_epochs': 100, 'verbosity': 1}\n",
    "\n",
    "_,_ = run(hparams, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum with prior shift\n",
    "hparams = {'optimize_probabilities': True, 'reduction': 'sum', 'prior_shift': True, 'lr': 3,\n",
    "           'total_epochs': 100, 'verbosity': 1}\n",
    "\n",
    "_,_ = run(hparams, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition without prior shift\n",
    "hparams = {'optimize_probabilities': True, 'reduction': 'condition', 'prior_shift': False, 'lr': 3,\n",
    "           'total_epochs': 100, 'verbosity': 1}\n",
    "\n",
    "_,_ = run(hparams, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition with prior shift\n",
    "hparams = {'optimize_probabilities': True, 'reduction': 'condition', 'prior_shift': True, 'lr': 3,\n",
    "           'total_epochs': 100, 'verbosity': 1}\n",
    "\n",
    "_,_ = run(hparams, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
