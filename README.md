# 人工智能安全理论及验证平台VoAI发布

## 引言

随着人工智能技术的发展，人工智能在越来越多的场景中替代或者辅助人类，不断提高生产效率、优化生活品质以及促进跨领域合作。更先进的人工智能技术一直是业界企业和高校不断探求和追逐的热点。尽管AI技术在诸多领域的应用取得显著成效，但广泛使用中暴露出安全风险却不容忽视与低估。

例如，通过添加精心构造的噪声到原始数据来误导无模型决策错误，在交通标志上添加噪声导致L4级车辆自动驾驶系统决策错误。通过在模型中嵌入后门，攻击者可以在特定条件下触发，在人脸录入时嵌入后门导致安防门禁无法阻止非法用户。大模型也难以独善其身，在经过恶意诱导后出现大模型越狱，甚至扬言设计恶意软件入侵银行系统。当前热门的模型，如OpenAI的ChatGPT、谷歌的Bard、Anthropic的Claude 2以及Meta的LLaMA-2，都无一幸免。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/36223bfb-9b2a-4faa-8fcb-8b12976bb518.png "自动驾驶对抗场景")![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/209fa0e4-0454-4df2-8247-c29806225722.png?x-oss-process=image/crop,x_0,y_0,w_640,h_357 "大模型越狱")

人工智能安全事故频发的根源，一方面在于人工智能系统具备从数据、模型、算法、框架、系统的长链路结构，每个环节都可能遭受各类威胁的侵扰；另一方面，AI系统容易受到多角度攻击，如各种各样的对抗攻击和后门攻击，而目前的安全评测方法又相对不足。同时，由于人工智能系统的保护机制设计较为孤立，所能覆盖的环节有限，防御策略也较为固定，这些因素共同限制了AI系统的防御效能。

## 人工智能安全理论及验证平台VoAI

浙江大学人工智能团队长期深耕人工智能领域，致力于发展AI安全，于近日正式发布并开源**人工智能安全理论及验证平台VoAI**平台**。**平台旨在对AI系统的全链路和全生命周期威胁进行感知与安全评估、提供安全防御策略，具备**全链路威胁感知**、**多维度安全评估**和**动态安全防御**三大特点，显著提升了人工智能系统的威胁监测、预警和响应能力，减少了由AI系统脆弱性引起的安全风险，为人工智能产业的安全发展提供了强大的动力。

### 全链路威胁感知：打破传统安全边界的限制，实现全链路覆盖

在传统观念中，AI安全边界的防护主要集中在数据安全、模型安全和应用安全三个方面。然而，VoAI打破了这一传统观念，实现了对全链路的覆盖。它不仅关注数据和模型，还将安全防护拓展至AI系统的每一个环节，包括智能数据、模型算法、开发框架以及操作系统等。通过全链路的威胁感知，我们能够更准确地把握AI系统的安全状态，及时发现并解决潜在的安全隐患，从而增强AI系统的安全性和可靠性。这种感知能力也为AI系统的优化和改进提供了强有力的支持，帮助我们更好地应对日益复杂多变的安全威胁。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/7b35ec49-1893-4a79-a5fb-cf03d1ace131.png "全链路危险感知")

*   AI数据面临多重安全威胁：训练数据可能被污染，例如在分类算法中，攻击者恶意混入了毒化数据，导致分类错误；应用输入数据可能被篡改，如攻击者使用对抗样本欺骗人工智能系统，让其做出错误的判断。VoAI平台可对上传的数据集进行异常数据检测以及公平性评估，评估数据集质量，并提供修复与公平性提升功能，提升数据集质量。
    

*   AI模型的脆弱性：AI模型的脆弱性表现为微小的数据错误就会使系统发生故障。例如。在图像识别中，图片中加入肉眼无法察觉的微小扰动，可能会导致人工智能系统发生紊乱。平台采用了基于注意力机制和模型预测置信度信息的双通道对抗样本检测技术，实现了60多种对抗攻击的感知。此外还集成了6种后门攻击检测算法，感知后门攻击。
    

*   AI算法 黑盒 风险：神经网络模型的深度增加和参数空间的复杂化，提升了图像、语音和文本识别等任务性能的同时，也使模型内部逻辑难以理解，这对医疗和自动驾驶等高可靠性支撑场景构成重大隐患。平台通过攻击机理分析研究各类对抗性攻击的生成与作用机理，追寻其误导模型的内在原因，并使用易于人类理解的解释方法展示风险。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/collab/jP2lR4zeY27Bq8g5/23bf790e-115d-45e3-8cd9-5d7dab2ce677.png "AI算法“黑盒”")

*   AI框架与操作系统漏洞频发：AI框架可以帮助开发者高效、快速地构建网络模型进行训练和推理，具有高效、便捷的特性。然而，在便捷高效的表象之下，人工智能框架也存在许多问题与风险。目前，平台支持Windows、Ubuntu、CentOS这三种操作系统以及TensorFlow、PyTorch、百度飞桨、CNTK、Theano这五种主流开发框架的安全度量。该技术能够在这些主流开发框架上实现高准确率、高效率、高通用性的漏洞检测，其检测误报率低于3%，这一结果优于国内外现有技术的检测结果。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/2633c160-de5a-4a4d-ba54-0cfc74b7bb38.png?x-oss-process=image/crop,x_7,y_10,w_806,h_472 "框架开发团队确认修复漏洞公告 ")

## 多维度安全评估：系统多维评估，实现全方位安全评测

针对AI系统模型鲁棒、数据安全和运行环境安全等方面的安全挑战，平台从鲁棒性、公平性、完整性、可用性、可解释性、可验证性六大维度对AI系统进行全面评估，全方位审视AI系统的安全性；六大维度安全性评测是人工智能系统多维度综合评估的创新性探索，帮助业界更好的评价人工智能系统，促进AI规模化落地。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/680b65e5-566a-490c-a815-6d9f4b647da2.png)

*   **鲁棒性**是对智能模型受到扰动与攻击能否稳定运行的评估。平台已集成了60多种主流的对抗样本生成算法，其中包括50种经典白盒对抗攻击和11种黑盒攻击，以全面评估AI模型的抗攻击能力。此外还引入了6种后门攻击，旨在挖掘模型更多的潜在漏洞。以VoAI在开源模型ResNet上的攻击评测结果为例，使用CIFAR10数据集进行测试。结果显示60多种攻击算法中，一半以上算法的攻击成功率超过90%，即图像分类任务准确率大大降低。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/a/pAgjegM24SGZZyBq/27c8f334ed134d86a4ca1f2878156bf31208.png "人工智能系统攻击结果")

*   **公平性**是对人工智能系统中的数据与模型是否存在偏见与歧视性决策的评估。平台实现了一个全面 且高可用的人工智能公平性评估与提升功能。该功能模块从公平性准则的角度覆盖了群体公平性和个体公平性；从评估对象的角度覆盖了数据集公平性与模型公平性。并针对两个对象提供了公平性评估和提升功能。平台拥有超过30种评估指标，能够实现精准的公平性评估与公平性优化治理。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/3da099a2-e15d-4c23-9489-bfb41803879f.png)

*   **完整性**是对数据在生命周期内是否遭到破坏的评估，如被添加格式异常数据、毒化数据等，为模型训练或部署提供数据保障。数据是系统的基础，平台支持表格、文本、图像3种模态的数据类型，可检测离群值、编码格式异常、毒化标签异常等4种频发异常。人工智能数据的完整性可以从根源上为人工智能系统安全提供保障，是人工智能系统正确决策和有效运行的根本。
    

*   **可用性**是对开发框架、操作系统进行兼容性匹配与漏洞检测，确保软件层和应用层安全可用。平台的开发环境分析功能，可以对不同操作系统下的系统架构信息、依赖库版本、AI开发框架依赖与版本等关键信息进行分析与记录，挖掘系统潜在的漏洞问题。框架适配功能，对于用户指定的开发框架，在框架功能适配模块中进行一系列的分析和比对操作。这包括对开发框架的版本、依赖库等信息进行核实，判断当前环境是否可以使用该框架功能。如果当前环境无法使用该框架功能，那么会生成一份报告，详细说明存在的问题和限制。
    

*   **可解释性**指能够清晰、透明地解释算法做出的决策或预测的过程。VoAI平台通过8种可解释性方法，如征归因可视化、数据分布降维可视化、模型内部特征分析可视化，深入分析攻击行为内在机理，并使用易于用户理解的方式可视化展示。特征归因可视化通过解释算法计算模型在正常样本和对抗样本上的显著图，并做可视化标注处理和展示，如下展示的是牧羊犬在不同解释算法下的显著图，可以看到对抗样本显著改变模型关注的特征区域，从狗脸移到了边缘位置，说明模型关注区域发生了偏移。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/9c4e802f-3035-4fdd-ad6e-ef960df0a4f8.png)

*   **可验证性**通过数学工具对算法模型的潜在行为空间进行理论分析，采用形式化验证方法有助于理解无限的行为模式，从而实现主流AI系统安全特性的快速验证。深度度学习模型在任意扰动的作用下可能出现输出不符合预期的情况，平台的形式化验证通过模型特征安全性验证、模型一致性验证、输出空间可达性验证，能够直观的展示模型在特定应用场景下的输出是否符合预期。
    

## 动态安全防御：打破孤立保护机制，实现群智增强防御

VoAI平台在感知与评估的基础上，针对AI模型保护机制设计孤立、覆盖环节有限、防御策略固定等特点，提出了群智增强的AI模型防御方法。突破防御智能体结构设计、智能体博弈机制、群体智能防御算法等关键技术，实现了基于群体智能的模型安全动态防御，即攻防博弈推演与群智增强防御。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/140cd90f-7904-4237-a608-ff3ba1cb5017.png)

*   攻防博弈推演：团队在对抗样本攻防博弈领域，将攻防对抗视为一个双人博弈问题，其中防御算法和攻击算法分别扮演双方，采用防御算法的收益函数作为评估指标，生成一个收益矩阵从而确定特定场景下的最优攻防策略，实现攻防博弈推演功能。功能模块中集成60多种对抗样本生成算法作为攻击策略选择，采用不同的攻击算法进行对抗训练作为防御策略。通过这种非对称能力的群体博弈算法，最终得到攻守双方的收益矩阵，选出特定场景下的最优攻防策略。
    

*   平台群智增强防御提供了鲁棒性训练和集成防御功能。鲁棒性训练通过特征散射、异常感知、随机平滑、对抗训练等方法提升深度学习模型和图神经网络的稳定性和准确性。鲁棒性训练的目的是使模型在面对对抗样本等不同的场景下都能表现良好。然而使用一种的对抗样本进行对抗训练，在应对其他类型的攻击算法方面效果却不尽如人意。针对这个问题，平台实现了一种基于多种攻击算法的集成防御算法，通过使用多种攻击算法生成的对抗样本分别进行对抗训练，综合多个训练结果组成最终分类模型，从而提升模型应对不同类型对抗样本生成算法的鲁棒性。
    

## 为大模型的发展保驾护航

人工智能已迈入大模型时代，大模型为大量下游领域提供支撑，应用广泛。国内大模型的发展也相当迅速，推出许多大模型应用，如百度的文心一言，复旦大学的MOSS，阿里的通义千问等，竞争激烈。

相对于传统AI算法，大模型具有新的特性和风险。大模型数据来源多样，但同样面临更大的攻击安全风险。大模型具有智能涌现特性，应用场景剧增，赋能下游应用技术升级，但同质化严重，大模型的任何改变都会影响整个社区，包括其存在的安全缺陷。

大模型的各方面性能普遍优于普通的AI模型，但仍面临传统的安全问题，例如隐私泄露，对抗攻击，歧视等安全风险。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/ABmOorDZDX9eqawZ/img/28f2946b-5ac9-49f0-9686-bb8105b01b85.png)

VoAI平台紧跟时代步伐，构建起大模型安全测评能力。针对多项中英文任务，使用BoolQ和MMLU对17个主流开源大模型进行鲁棒性评测，大模型平均准确率下降达8.80%，可以看出开源的大模型存在不同程度的鲁棒性不足问题，轻微的扰动对大模型性能的影响较大。未来，团队还将更进一步实现覆盖大模型全生命周期安全的测评能力建设，重点对大模型后门攻击威胁、毒化攻击威胁、输出内容鲁棒性、越狱安全风险、软件框架安全性等大模型安全问题进行评测。

## 结语

人工智能安全理论及验证平台VoAI提供了一个深度学习模型和大模型安全评测的综合型解决方案，填补了现有工具的空白，为AI安全提供更为全面、有效地保障。

人工智能安全团队负责人为浙江大学区块链与数据安全全国重点实验室常务副主任、计算机学院院长任奎教授，由浙江大学、武汉大学、西安交通大学、南京航空航天大学、西北工业大学、淘宝（中国）软件有限公司、山东省计算中心（国家超级计算济南中心）、中国人民公安大学、湖南四方天箭信息科技有限公司联合组建。团队包含多名教授和几十名博士、硕士研究生，研究成果覆盖人工智能系统各个层次，包含硬件、操作系统、软件、攻击、防御，已发表计算机安全、人工智能顶会论文100余篇，其中多篇获得最佳论文奖。团队积极响应国家号召，抢占人工智能技术制高点，妥善应对人工智能带来的安全新问题，实现关键技术自主可控。